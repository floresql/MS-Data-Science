{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af34cff-e309-4338-999e-9db34fbf2e66",
   "metadata": {},
   "source": [
    "# Week 6 Lab Part 2\n",
    "## Model Training, Testing, and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ba50b-4d80-4782-a53a-8f8acf3fdc5f",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da7ec5bb-698c-4c96-b328-ee1cb6e26b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the file path for the saved model\n",
    "model_file_path = \"Week6_model.joblib\"\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load(model_file_path)\n",
    "X_val = load(\"X_val.joblib\")\n",
    "y_val = load(\"y_val.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c561cb-8bc4-49ab-bdf2-9e597bbb47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_val_pred = loaded_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25c2fee-238c-4919-bf46-a778f1e2e505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a43842c-378a-4345-8765-32bef44d894d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val,y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3caf3-d277-45b9-ace8-41e7d217b213",
   "metadata": {},
   "source": [
    "# **Week 6 Lab Summary: Model Training, Testing, and Validation**\n",
    "\n",
    "## **1. Data Loading and Feature Engineering**\n",
    "- I connected to a **PostgreSQL** database and pulled in the `sales_transaction` dataset.\n",
    "- I engineered new features:\n",
    "  - **Total Purchase Frequency** (number of purchases per customer).\n",
    "  - **Total Revenue Per Customer** (sum of `Price * Quantity` for each customer).\n",
    "  - Created a **Repeat Customer** label (`1` if `Total_Purchase_Frequency > 1`, else `0`).\n",
    "\n",
    "## **2. Data Splitting**\n",
    "- I split the dataset into:\n",
    "  - **Train (70%)**\n",
    "  - **Validation (15%)**\n",
    "  - **Test (15%)**\n",
    "\n",
    "## **3. Model Training**\n",
    "- I trained a **Random Forest Classifier** (`n_estimators=100, random_state=42`) using the training data.\n",
    "- After training, I saved both the model and the validation dataset using **joblib**.\n",
    "\n",
    "## **4. Model Validation in Another Notebook**\n",
    "- I loaded the **saved model**, **X_val**, and **y_val** in a separate notebook.\n",
    "- I made predictions on **y_val_pred** and calculated the accuracy score.\n",
    "- The accuracy came out to **1.0**, which is way too highâ€”definitely suspicious.\n",
    "\n",
    "---\n",
    "\n",
    "## **Possible Issues: Why Is My Model Too Perfect?**\n",
    "1. **Data Leakage?**  \n",
    "   - If `Total_Purchase_Frequency` was calculated using all data (instead of just training data), my model might be \"cheating\" by learning from information it shouldn't have.\n",
    "\n",
    "2. **Overfitting?**  \n",
    "   - **Random Forest with 100 trees** can overfit, especially if the dataset is small or if there's a dominant feature.\n",
    "   - I might need to reduce `n_estimators` or limit the `max_depth`.\n",
    "\n",
    "3. **Target Leakage?**  \n",
    "   - If `Total_Revenue` includes future transactions, the model has unfair access to future outcomes, making predictions too easy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Next Steps**\n",
    "- **Check for data leakage**: I need to make sure my computed features donâ€™t use future data when making predictions.\n",
    "- **Try a simpler model**: Running a **Logistic Regression** or a shallow decision tree would help see if the issue persists.\n",
    "- **Look at feature importance**: Using `.feature_importances_` on my Random Forest model could reveal if a single feature is dominating the predictions.\n",
    "\n",
    "This accuracy score is **too good to be true**, so I need to dig deeper! ðŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f19fcd-9706-47f4-beaa-0e12ef79edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
